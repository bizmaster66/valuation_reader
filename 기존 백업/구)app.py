import os
import json
from datetime import datetime
import hashlib

import streamlit as st

from src.evaluator import run_evaluation, compute_weighted_total, summarize_short, run_detail_feedback
from src.gemini_client import get_client
from src.pdf_reader import extract_pages
from src.storage import append_history, load_history
from src.startup_analyzer_adapter import (
    generate_company_profile,
    extract_industry_keywords,
    generate_industry_report,
)
from src.presets import EVAL_ITEMS, merge_presets


# -----------------------------
# Helpers
# -----------------------------
def save_uploaded_pdf(uploaded) -> str:
    os.makedirs("data/uploads", exist_ok=True)
    path = os.path.join("data/uploads", uploaded.name)
    with open(path, "wb") as f:
        f.write(uploaded.getbuffer())
    return path


def write_md(path: str, content: str) -> None:
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        f.write(content)


def safe_json_load(text: str):
    try:
        return json.loads(text)
    except Exception:
        s = text.find("{")
        e = text.rfind("}")
        if s != -1 and e != -1 and e > s:
            return json.loads(text[s:e+1])
        return {"error": "JSON parse failed", "raw": text}


def build_packed_text(pages, limit_chars: int = 60000) -> str:
    parts = []
    for p in pages:
        t = (p.get("text") or "").strip()
        if t:
            parts.append(f"[PAGE {p['page']}]\n{t}")
    packed = "\n\n".join(parts)
    return packed[:limit_chars]


# -----------------------------
# Streamlit UI
# -----------------------------
st.set_page_config(page_title="AI ì‹¬ì‚¬ì—­ (MVP+)", layout="wide")
st.title("AI ì‹¬ì‚¬ì—­ (MVP+) â€” PDF â†’ ê¸°ì—…ëª…/ëŒ€í‘œì â†’ íšŒì‚¬ì •ë³´/ì‚°ì—…ë¦¬í¬íŠ¸ â†’ BM/ì‚°ì—…/ë‹¨ê³„+ê°€ì¤‘ì¹˜")

if "eval_cache" not in st.session_state:
    st.session_state.eval_cache = {}
if "detail_cache" not in st.session_state:
    st.session_state.detail_cache = {}

st.sidebar.header("ì˜µì…˜")
use_company_profile = st.sidebar.toggle("íšŒì‚¬ ì •ë³´ ì •ì˜(í™ˆí˜ì´ì§€/ë‰´ìŠ¤) ì‹¤í–‰", value=True)
use_industry_report = st.sidebar.toggle("ì‚°ì—… ë¦¬í¬íŠ¸ ìƒì„±", value=True)
use_classification = st.sidebar.toggle("BM/ì‚°ì—…/ë‹¨ê³„ ì¶”ì²œ + ê°€ì¤‘ì¹˜ UI", value=True)

if st.sidebar.button("ì „ì²´ ë¦¬ì…‹"):
    st.session_state.run_pipeline = False
    st.session_state.eval_cache = {}
    st.session_state.detail_cache = {}
    st.rerun()

uploaded_files = st.file_uploader(
    "IR PDF ì—…ë¡œë“œ (ìµœëŒ€ 10ê°œ)",
    type=["pdf"],
    accept_multiple_files=True
)

run_btn = st.button("ë¶„ì„ ì‹¤í–‰", type="primary", disabled=not uploaded_files)

if "run_pipeline" not in st.session_state:
    st.session_state.run_pipeline = False

if run_btn:
    st.session_state.run_pipeline = True



# -----------------------------
# Main
# -----------------------------
if st.session_state.run_pipeline:
    try:
        client = get_client()
    except Exception as e:
        st.error(f"Gemini í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        st.stop()

    for up in uploaded_files[:10]:
        import hashlib
        file_bytes = up.getvalue()
        file_key = hashlib.md5(file_bytes).hexdigest()[:10]
        key_base = file_key
        cache_key = file_key

        st.markdown("---")
        st.subheader(f"íŒŒì¼: {up.name}")

        pdf_path = save_uploaded_pdf(up)
        pages = extract_pages(pdf_path)
        packed_text = build_packed_text(pages, limit_chars=60000)

        # 1) ê¸°ì—…ëª…/ëŒ€í‘œì ì¶”ì¶œ
        extract_prompt = (
            "ë„ˆëŠ” IR PDFë¥¼ ì½ê³  'ê¸°ì—…ëª…'ê³¼ 'ëŒ€í‘œì ì„±ëª…'ì„ ì°¾ì•„ì•¼ í•œë‹¤.\n"
            "ì¶”ì •í•˜ì§€ ë§ê³ , ë¬¸ì„œì— ëª…ì‹œëœ ê·¼ê±° í˜ì´ì§€ì™€ ì§§ì€ ì¸ìš©(ë¬¸ì¥ ì¼ë¶€)ì„ í•¨ê»˜ ì œì‹œí•˜ë¼.\n\n"
            "ì¶œë ¥ì€ JSON ONLYì´ë©° í•„ë“œëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤:\n"
            "- company_name\n"
            "- ceo_name\n"
            "- evidence: page, quote\n\n"
            "IR í…ìŠ¤íŠ¸:\n"
        ) + packed_text

        resp = client.models.generate_content(model="gemini-2.5-flash", contents=extract_prompt)
        extracted = safe_json_load((resp.text or "").strip())

        company = extracted.get("company_name") or "unknown_company"
        ceo = extracted.get("ceo_name") or "unknown_ceo"

        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        out_dir = f"data/outputs/{company}/{ts}"

        # 00_extract.md ì €ì¥
        md_extract = (
            f"# ê¸°ì—…ëª…/ëŒ€í‘œì ì¶”ì¶œ ê²°ê³¼\n"
            f"- íŒŒì¼: {up.name}\n\n"
            f"## ì¶”ì¶œ\n"
            f"- ê¸°ì—…ëª…: {company}\n"
            f"- ëŒ€í‘œì: {ceo}\n\n"
            f"## ê·¼ê±°(evidence)\n"
            f"{json.dumps(extracted.get('evidence', []), ensure_ascii=False, indent=2)}\n"
        )
        write_md(f"{out_dir}/00_extract.md", md_extract)

        tab1, tab2, tab3, tab4 = st.tabs(["00 ì¶”ì¶œ", "01 íšŒì‚¬ ì •ë³´", "02 ì‚°ì—… ë¦¬í¬íŠ¸", "03 ë¶„ë¥˜/ê°€ì¤‘ì¹˜"])

        with tab1:
            st.json(extracted)
            st.caption(f"ì €ì¥ë¨: {out_dir}/00_extract.md")

        profile = {}
        profile_sources = []
        industry_text = ""
        industry_sources = []

        # 2) íšŒì‚¬ ì •ë³´ ì •ì˜
        if use_company_profile and company != "unknown_company":
            with tab2:
                st.info("íšŒì‚¬ ì •ë³´ ì •ì˜ ì¤‘(í™ˆí˜ì´ì§€/ë‰´ìŠ¤ ê²€ìƒ‰ ê¸°ë°˜)...")
            try:
                profile, profile_sources = generate_company_profile(client, company, ceo)

                md_profile = (
                    f"# íšŒì‚¬ ì •ë³´ ì •ì˜(í™ˆí˜ì´ì§€/ë‰´ìŠ¤ ê¸°ë°˜)\n"
                    f"- íšŒì‚¬ëª…: {company}\n"
                    f"- ëŒ€í‘œì: {ceo}\n\n"
                    f"## ê²°ê³¼(JSON)\n"
                    f"```json\n{json.dumps(profile, ensure_ascii=False, indent=2)}\n```\n\n"
                    f"## ì¶œì²˜(grounding)\n"
                    f"{json.dumps(profile_sources, ensure_ascii=False, indent=2)}\n"
                )
                write_md(f"{out_dir}/01_company_profile.md", md_profile)

                with tab2:
                    st.success("ì™„ë£Œ")
                    st.json(profile)
                    if profile_sources:
                        st.caption("ì¶œì²˜ ì¼ë¶€(ìƒìœ„ 10ê°œ)")
                        st.write(profile_sources[:10])
                    st.caption(f"ì €ì¥ë¨: {out_dir}/01_company_profile.md")
            except Exception as e:
                with tab2:
                    st.error(f"íšŒì‚¬ ì •ë³´ ì •ì˜ ì‹¤íŒ¨: {e}")
        else:
            with tab2:
                st.caption("ì˜µì…˜ì´ êº¼ì ¸ìˆê±°ë‚˜ íšŒì‚¬ëª…ì´ í™•ì¸ ë¶ˆê°€ì—¬ì„œ íšŒì‚¬ ì •ë³´ ì •ì˜ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")

        # 3) ì‚°ì—… ë¦¬í¬íŠ¸
        if use_industry_report and profile:
            with tab3:
                st.info("ì‚°ì—… ë¦¬í¬íŠ¸ ìƒì„± ì¤‘(ê²€ìƒ‰ ê¸°ë°˜)...")
            try:
                kws = extract_industry_keywords(profile)
                industry_text, industry_sources = generate_industry_report(client, kws)

                md_industry = (
                    f"# ì‚°ì—… ë¦¬í¬íŠ¸(ê²€ìƒ‰ ê¸°ë°˜)\n"
                    f"- í‚¤ì›Œë“œ: {', '.join(kws)}\n\n"
                    f"## ë¦¬í¬íŠ¸\n"
                    f"{industry_text}\n\n"
                    f"## ì¶œì²˜(grounding)\n"
                    f"{json.dumps(industry_sources, ensure_ascii=False, indent=2)}\n"
                )
                write_md(f"{out_dir}/02_industry_report.md", md_industry)

                with tab3:
                    st.success("ì™„ë£Œ")
                    st.markdown(industry_text)
                    if industry_sources:
                        st.caption("ì¶œì²˜ ì¼ë¶€(ìƒìœ„ 10ê°œ)")
                        st.write(industry_sources[:10])
                    st.caption(f"ì €ì¥ë¨: {out_dir}/02_industry_report.md")
            except Exception as e:
                with tab3:
                    st.error(f"ì‚°ì—… ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        else:
            with tab3:
                st.caption("ì˜µì…˜ì´ êº¼ì ¸ìˆê±°ë‚˜ profileì´ ì—†ì–´ì„œ ì‚°ì—… ë¦¬í¬íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")

        # 4) BM/ì‚°ì—…/ë‹¨ê³„ ì¶”ì²œ + ê°€ì¤‘ì¹˜ UI
        bm_final = ""
        industry_final = ""
        stage_final = ""
        weights_final = {}

        if use_classification:
            context = {
                "company_name": company,
                "ceo_name": ceo,
                "ir_text_excerpt": packed_text[:8000],
                "company_profile": profile if profile else {},
            }

            classify_prompt = (
                "ë„ˆëŠ” ìŠ¤íƒ€íŠ¸ì—… IR ì‹¬ì‚¬ì—­ì´ë‹¤.\n"
                "ì•„ë˜ ì…ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸(BM), ì‚°ì—… ë¶„ì•¼(Industry), íˆ¬ììœ ì¹˜ ë‹¨ê³„(Stage)ë¥¼ ì¶”ì²œí•˜ë¼.\n"
                "ì¶”ì •ì´ ì–´ë µë‹¤ë©´ 'í™•ì¸ ë¶ˆê°€'ë¼ê³  ì“°ê³  ì´ìœ ë¥¼ ì§§ê²Œ ì¨ë¼.\n"
                "ì¶œë ¥ì€ JSON ONLYì´ë©° í•„ë“œëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤:\n"
                "- business_model (ì˜ˆ: SaaS/í”Œë«í¼/ì œì¡°/ë”¥í…Œí¬/ë°”ì´ì˜¤/ì»¤ë¨¸ìŠ¤/ì½˜í…ì¸ /ê¸°íƒ€)\n"
                "- industry (ì˜ˆ: ëª¨ë¹Œë¦¬í‹°/í—¬ìŠ¤ì¼€ì–´/í•€í…Œí¬/AI/êµìœ¡/ë¦¬í…Œì¼/ê¸°íƒ€)\n"
                "- stage (ì˜ˆ: Pre-seed/Seed/Series A/Series B+/í™•ì¸ ë¶ˆê°€)\n"
                "- reason (ê·¼ê±° 3~6ë¬¸ì¥)\n\n"
                "ì…ë ¥:\n"
            ) + json.dumps(context, ensure_ascii=False)

            try:
                r_cls = client.models.generate_content(model="gemini-2.5-flash", contents=classify_prompt)
                cls = safe_json_load((r_cls.text or "").strip())
            except Exception as e:
                cls = {"business_model": "", "industry": "", "stage": "", "reason": f"ì¶”ì²œ ì‹¤íŒ¨: {e}"}

            bm_s = (cls.get("business_model") or "").strip()
            ind_s = (cls.get("industry") or "").strip()
            stg_s = (cls.get("stage") or "").strip()
            reason = (cls.get("reason") or "").strip()

            bm_options = ["SaaS", "í”Œë«í¼", "ì œì¡°", "ë”¥í…Œí¬", "ë°”ì´ì˜¤", "ì»¤ë¨¸ìŠ¤", "ì½˜í…ì¸ ", "ê¸°íƒ€"]
            ind_options = ["ëª¨ë¹Œë¦¬í‹°", "í—¬ìŠ¤ì¼€ì–´", "í•€í…Œí¬", "AI", "êµìœ¡", "ë¦¬í…Œì¼", "ê¸°íƒ€"]
            stage_options = ["Pre-seed", "Seed", "Series A", "Series B+", "í™•ì¸ ë¶ˆê°€"]

            def pick_default(options, suggested):
                return suggested if suggested in options else options[-1]

            # Streamlit ìœ„ì ¯ í‚¤(íŒŒì¼ë³„ ì¶©ëŒ ë°©ì§€)
            key_base = file_key

            with tab4:
                st.subheader("BM / ì‚°ì—… / íˆ¬ìë‹¨ê³„ ì¶”ì²œ ë° í™•ì •")
                c1, c2, c3 = st.columns(3)
                with c1:
                    bm_final = st.selectbox(
                        "ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸(BM)",
                        bm_options,
                        index=bm_options.index(pick_default(bm_options, bm_s)),
                        key=f"{key_base}_bm",
                    )
                with c2:
                    industry_final = st.selectbox(
                        "ì‚°ì—… ë¶„ì•¼(Industry)",
                        ind_options,
                        index=ind_options.index(pick_default(ind_options, ind_s)),
                        key=f"{key_base}_ind",
                    )
                with c3:
                    stage_final = st.selectbox(
                        "íˆ¬ììœ ì¹˜ ë‹¨ê³„(Stage)",
                        stage_options,
                        index=stage_options.index(pick_default(stage_options, stg_s)),
                        key=f"{key_base}_stg",
                    )

                if reason:
                    st.caption(f"ì¶”ì²œ ê·¼ê±°: {reason}")

                st.divider()
                st.subheader("ê°€ì¤‘ì¹˜(ì¶”ì²œ preset) â†’ ìˆ˜ì • ê°€ëŠ¥")

                w = merge_presets(bm_final, stage_final)
                edited = {}
                for k in EVAL_ITEMS:
                    edited[k] = st.slider(
                        k,
                        min_value=0.0,
                        max_value=0.30,
                        value=float(w.get(k, 0.0)),
                        step=0.01,
                        key=f"{key_base}_w_{k}",
                    )

                ssum = sum(edited.values()) or 1.0
                weights_final = {k: v / ssum for k, v in edited.items()}
                st.caption(f"ì •ê·œí™” í•©ê³„: {sum(weights_final.values()):.2f}")

            md_cls = (
                f"# BM/ì‚°ì—…/íˆ¬ìë‹¨ê³„ ë° ê°€ì¤‘ì¹˜ í™•ì •\n"
                f"- íšŒì‚¬ëª…: {company}\n"
                f"- ëŒ€í‘œì: {ceo}\n\n"
                f"## ì¶”ì²œ\n"
                f"- BM(ì¶”ì²œ): {bm_s}\n"
                f"- ì‚°ì—…(ì¶”ì²œ): {ind_s}\n"
                f"- ë‹¨ê³„(ì¶”ì²œ): {stg_s}\n\n"
                f"## í™•ì •\n"
                f"- BM(í™•ì •): {bm_final}\n"
                f"- ì‚°ì—…(í™•ì •): {industry_final}\n"
                f"- ë‹¨ê³„(í™•ì •): {stage_final}\n\n"
                f"## ì¶”ì²œ ê·¼ê±°\n{reason}\n\n"
                f"## ê°€ì¤‘ì¹˜(ì •ê·œí™”)\n"
                f"```json\n{json.dumps(weights_final, ensure_ascii=False, indent=2)}\n```\n"
            )
            write_md(f"{out_dir}/03_classification_and_weights.md", md_cls)

        # 5) ì¢…í•© í‰ê°€(0~5, í˜ì´ì§€ ê·¼ê±°, ì´ì  0~100, 80ì  ì¶”ì²œì„œ ë¶„ê¸°)
        with tab4:
            st.divider()
            st.subheader("AI ì‹¬ì‚¬ì—­ ì¢…í•© í‰ê°€")

            do_eval = st.button("ì¢…í•© í‰ê°€ ìƒì„±", key=f"{key_base}_do_eval")

            # ìºì‹œ ìƒíƒœ í‘œì‹œ(í•­ìƒ)
            cached = st.session_state.eval_cache.get(cache_key)
            st.caption(f"[ë””ë²„ê·¸] cache_key={cache_key} / cached={'YES' if cached else 'NO'}")
            if cached:
                st.metric("ì´ì (0~100)", cached["total_score"])
                st.caption(f"í†¤: {cached['tone']}")
                st.caption(f"ì €ì¥ ê²½ë¡œ: {cached['out_dir']}/04_evaluation.md")

            # ë²„íŠ¼ ëˆŒë €ì„ ë•Œë§Œ í‰ê°€ ìˆ˜í–‰
            if do_eval:
                try:
                    bm_for_eval = bm_final or "í™•ì¸ ë¶ˆê°€"
                    industry_for_eval = industry_final or "í™•ì¸ ë¶ˆê°€"
                    stage_for_eval = stage_final or "í™•ì¸ ë¶ˆê°€"

                    # ê°€ì¤‘ì¹˜ ê¸°ë³¸ê°’ ë³´ì •(í™•ì¸ë¶ˆê°€ë©´ ì•ˆì „í•œ ê¸°ë³¸ í”„ë¦¬ì…‹ ì‚¬ìš©)
                    if weights_final:
                        weights_for_eval = weights_final
                    else:
                        bm_seed = bm_for_eval if bm_for_eval != "í™•ì¸ ë¶ˆê°€" else "SaaS"
                        stg_seed = stage_for_eval if stage_for_eval != "í™•ì¸ ë¶ˆê°€" else "Seed"
                        weights_for_eval = merge_presets(bm_seed, stg_seed)

                    evaluation = run_evaluation(
                        client=client,
                        model_name="gemini-2.5-flash",
                        company=company,
                        ceo=ceo,
                        packed_text=packed_text,
                        bm=bm_for_eval,
                        industry=industry_for_eval,
                        stage=stage_for_eval,
                        weights=weights_for_eval,
                    )

                    items = evaluation.get("items", []) or []
                    total_score = float(compute_weighted_total(items, weights_for_eval))
                    tone = "recommend" if total_score >= 80 else "critical"

                    evaluation["total_score_100"] = total_score
                    evaluation["tone"] = tone

                    # ìºì‹œì— ì €ì¥
                    st.session_state.eval_cache[cache_key] = {
                        "evaluation": evaluation,
                        "total_score": total_score,
                        "tone": tone,
                        "out_dir": out_dir,
                    }

                    # íŒŒì¼ ì €ì¥
                    write_md(f"{out_dir}/04_evaluation.json", json.dumps(evaluation, ensure_ascii=False, indent=2))

                    short = summarize_short(items)
                    md_eval = f"""# IR ì¢…í•© ë¶„ì„ í‰ê°€
- íšŒì‚¬ëª…: {company}
- ëŒ€í‘œì: {ceo}
- ì´ì (0~100): {total_score}
- í†¤: {tone}

## í•œì¤„ ìš”ì•½
{short}

## í•­ëª©ë³„ í‰ê°€(0~5)
"""
                    for it in items:
                        name = it.get("name", "")
                        score = it.get("score", "")
                        exempt = it.get("exempt", False)
                        pages = it.get("evidence_pages", [])
                        md_eval += f"\n### {name} â€” {score}ì " + (" (ë©´ì œ)" if exempt else "") + "\n"
                        md_eval += f"- ê·¼ê±° í˜ì´ì§€: {pages}\n"
                        md_eval += f"- âœ… ê°•ì : {it.get('strengths','')}\n"
                        md_eval += f"- âŒ ë³´ì™„: {it.get('weaknesses','')}\n"
                        if (not exempt) and (float(score or 0) <= 3):
                            md_eval += f"- ğŸ’¡ ì œì•ˆ: {it.get('suggestions','')}\n"
                        md_eval += f"- â“ ì§ˆë¬¸: {it.get('investor_questions','')}\n"

                    md_eval += "\n## ì¢…í•© ì½”ë©˜íŠ¸\n" + (evaluation.get("overall_commentary", "") or "")
                    if tone == "recommend":
                        rec = evaluation.get("recommendation_note", "") or ""
                        if rec:
                            md_eval += "\n\n## ì¶”ì²œ ì˜ê²¬(80ì  ì´ìƒ)\n" + rec

                    write_md(f"{out_dir}/04_evaluation.md", md_eval)

                    st.success("ì¢…í•© í‰ê°€ ìƒì„± ì™„ë£Œ")
                    st.metric("ì´ì (0~100)", total_score)
                    st.caption(short)
                    st.caption(f"ì €ì¥ë¨: {out_dir}/04_evaluation.md")

                except Exception as e:
                    st.error(f"ì¢…í•© í‰ê°€ ìƒì„± ì‹¤íŒ¨: {e}")
                
                append_history({
                    "company_name": company,
                    "ceo_name": ceo,
                    "bm": bm_for_eval,
                    "industry": industry_for_eval,
                    "stage": stage_for_eval,
                    "total_score": total_score,
                    "recommendation": "YES" if total_score >= 80 else "NO",
                    "file_name": up.name,
                    "output_path": out_dir
                })



        # 6) ìƒì„¸ í”¼ë“œë°±(ìš”ì²­ ì‹œ ìƒì„±)  âœ…ìºì‹œ ê¸°ë°˜ìœ¼ë¡œ ì•ˆì •í™”
        with tab4:
            st.divider()
            st.subheader("ìƒì„¸ í”¼ë“œë°±(ìš”ì²­ ì‹œ ìƒì„±)")
            do_detail = st.button("ìƒì„¸ í”¼ë“œë°± ìƒì„±", key=f"{key_base}_do_detail")

            # ìºì‹œëœ ìƒì„¸í”¼ë“œë°±ì´ ìˆìœ¼ë©´ í•­ìƒ ë³´ì—¬ì£¼ê¸°
            cached_d = st.session_state.detail_cache.get(cache_key)
            if cached_d:
                st.success("ìƒì„¸ í”¼ë“œë°±ì´ ì´ë¯¸ ìƒì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤(ë¦¬ì…‹ë˜ì§€ ì•ŠìŒ).")
                st.caption(f"ì €ì¥ ê²½ë¡œ: {cached_d['out_dir']}/05_detail_feedback.md")
                st.download_button(
                    "ìƒì„¸ í”¼ë“œë°± md ë‹¤ìš´ë¡œë“œ",
                    data=cached_d["detail_md"].encode("utf-8"),
                    file_name=f"{company}_detail_feedback.md",
                    key=f"{key_base}_dl_detail_cached",
                )

        if do_detail:
            # âœ… ì¢…í•©í‰ê°€ê°€ ìºì‹œì— ìˆëŠ”ì§€ í™•ì¸
            cached_eval = st.session_state.eval_cache.get(cache_key)
            if not cached_eval or not cached_eval.get("evaluation"):
                with tab4:
                    st.warning("ìƒì„¸ í”¼ë“œë°±ì„ ë§Œë“¤ë ¤ë©´ ë¨¼ì € 'ì¢…í•© í‰ê°€ ìƒì„±'ì„ ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤.")
            else:
                eval_json = cached_eval["evaluation"]

                try:
                    with tab4:
                        with st.spinner("ìƒì„¸ í”¼ë“œë°± ìƒì„± ì¤‘..."):
                            detail_md = run_detail_feedback(
                                client=client,
                                model_name="gemini-2.5-flash",
                                company=company,
                                ceo=ceo,
                                bm=bm_final or "í™•ì¸ ë¶ˆê°€",
                                industry=industry_final or "í™•ì¸ ë¶ˆê°€",
                                stage=stage_final or "í™•ì¸ ë¶ˆê°€",
                                evaluation_json=eval_json,
                            )

                    # íŒŒì¼ ì €ì¥
                    write_md(f"{out_dir}/05_detail_feedback.md", detail_md)

                    # âœ… ìºì‹œì— ì €ì¥(ë¦¬ì…‹ ë°©ì§€)
                    st.session_state.detail_cache[cache_key] = {
                        "detail_md": detail_md,
                        "out_dir": out_dir,
                    }

                    with tab4:
                        st.success("ìƒì„¸ í”¼ë“œë°± ìƒì„± ì™„ë£Œ")
                        st.caption(f"ì €ì¥ë¨: {out_dir}/05_detail_feedback.md")
                        st.download_button(
                            "ìƒì„¸ í”¼ë“œë°± md ë‹¤ìš´ë¡œë“œ",
                            data=detail_md.encode("utf-8"),
                            file_name=f"{company}_detail_feedback.md",
                            key=f"{key_base}_dl_detail_new",
                        )

                except Exception as e:
                    with tab4:
                        st.error(f"ìƒì„¸ í”¼ë“œë°± ìƒì„± ì‹¤íŒ¨: {e}")


        

# -----------------------------
# History view
# -----------------------------
st.markdown("## íˆìŠ¤í† ë¦¬")
hist = load_history()
st.dataframe(hist, use_container_width=True)

if not hist.empty:
    import io
    buf = io.BytesIO()
    hist.to_excel(buf, index=False)
    st.download_button("íˆìŠ¤í† ë¦¬ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ", data=buf.getvalue(), file_name="history.xlsx")
