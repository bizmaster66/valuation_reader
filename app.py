import os
import glob
import shutil
import time
import json
import hashlib
from datetime import datetime
import io
import inspect
import math
import matplotlib.pyplot as plt

import pandas as pd
import streamlit as st

from src.gemini_client import get_client
from src.storage import append_history, load_history
from src.startup_analyzer_adapter import generate_company_profile

from src.evaluator_simple import run_overall_evaluation  # evaluatorëŠ” ì„¹ì…˜ ì ìˆ˜/ë¶„ì„/ê°œì„ ì•ˆ/ìš”ì•½ ìƒì„±
from src.dataset_logger import upsert_ai_output, load_ai_outputs, AI_OUTPUT_PATH
from src.pdf_vision import gemini_pdf_visual_insights

from src.pdf_ocr_pages import ocr_pdf_all_pages
from src.weight_engine import WeightEngine


# -----------------------------
# 0) ê¸°ì¤€ ì„¹ì…˜(9ê°œ)
# -----------------------------
SECTIONS_KOR = [
    "ë¬¸ì œ ì •ì˜",
    "ì†”ë£¨ì…˜ & ì œí’ˆ",
    "ì‹œì¥ ë¶„ì„",
    "ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸",
    "ê²½ìŸ ìš°ìœ„",
    "ì„±ì¥ ì „ëµ",
    "íŒ€ ì—­ëŸ‰",
    "ì¬ë¬´ ê³„íš",
    "ë¦¬ìŠ¤í¬ ê´€ë¦¬",
]

KOR_TO_CRITERION = {
    "ë¬¸ì œ ì •ì˜": "problem_definition",
    "ì†”ë£¨ì…˜ & ì œí’ˆ": "solution_product",
    "ì‹œì¥ ë¶„ì„": "market",
    "ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸": "business_model",
    "ê²½ìŸ ìš°ìœ„": "competitive_advantage",
    "ì„±ì¥ ì „ëµ": "growth_strategy",
    "íŒ€ ì—­ëŸ‰": "team",
    "ì¬ë¬´ ê³„íš": "financial_plan",
    "ë¦¬ìŠ¤í¬ ê´€ë¦¬": "risk_management",
}


# -----------------------------
# 1) Helpers: WeightEngine ë§¤í•‘
# -----------------------------
def map_stage_for_engine(stage_raw: str) -> str:
    """
    WeightEngine normalize_stageê°€ aliasë¥¼ ì²˜ë¦¬í•˜ì§€ë§Œ,
    B+ / B ì´ìƒ ê°™ì€ ë³€í˜•ì€ ì•ˆì „í•˜ê²Œ ì—¬ê¸°ì„œ ë¨¼ì € ì •ê·œí™”.
    """
    s = (stage_raw or "").strip().lower()
    s = s.replace("_", " ").replace("-", " ").strip()

    if "b+" in s or "b ì´ìƒ" in s or "bì´ìƒ" in s or "b plus" in s:
        return "series_b"
    if "c+" in s or "c ì´ìƒ" in s or "cì´ìƒ" in s:
        return "series_c"

    if "seed" in s or "preseed" in s or "pre seed" in s or "pre-seed" in s:
        return "seed"
    if "pre a" in s or "pre-a" in s or "prea" in s:
        return "pre_a"
    if "series a" in s or s == "a":
        return "series_a"
    if "series b" in s or s == "b":
        return "series_b"
    if "series c" in s or s == "c":
        return "series_c"
    if "pre ipo" in s or "pre-ipo" in s:
        return "pre_ipo"
    if "ipo" in s:
        return "ipo"

    return "seed"


def map_industry_for_engine(industry_raw: str):
    """
    industry ë©€í‹°í”Œë¼ì´ì–´ í‚¤(ì˜ˆ: b2b_saas, deeptech ë“±)ë¡œ ë§¤í•‘.
    ë§¤í•‘ ì‹¤íŒ¨ ì‹œ None â†’ ë©€í‹°í”Œë¼ì´ì–´ ë¯¸ì ìš©.
    """
    s = (industry_raw or "").strip().lower()

    if "ë°”ì´ì˜¤" in s or "í—¬ìŠ¤" in s or "ì˜ë£Œ" in s:
        return "bio_healthcare"
    if "ë”¥í…Œí¬" in s or "ë¡œë´‡" in s or "ì†Œì¬" in s or "ë°˜ë„ì²´" in s:
        return "deeptech"
    if "ì œì¡°" in s or "ì†Œë¶€ì¥" in s:
        return "manufacturing_sobu"
    if "í”Œë«í¼" in s or "ë§ˆì¼“" in s or "ë§ˆì¼“í”Œë ˆì´ìŠ¤" in s:
        return "platform_marketplace"
    if "í•€í…Œí¬" in s or "ê¸ˆìœµ" in s:
        return "fintech_regulated"
    if "ì»¤ë¨¸ìŠ¤" in s or "ì‡¼í•‘" in s or "d2c" in s:
        return "d2c_commerce"
    if "saas" in s or "b2b" in s:
        return "b2b_saas"

    return None


def map_bm_for_engine(bm_raw: str):
    """
    business model multipliers í‚¤(subscription_saas ë“±)ë¡œ ë§¤í•‘.
    ë§¤í•‘ ì‹¤íŒ¨ ì‹œ None â†’ ë©€í‹°í”Œë¼ì´ì–´ ë¯¸ì ìš©.
    """
    s = (bm_raw or "").strip().lower()

    if "êµ¬ë…" in s or "subscription" in s:
        return "subscription_saas"
    if "usage" in s or "ì‚¬ìš©ëŸ‰" in s:
        return "usage_based"
    if "marketplace" in s or "ê±°ë˜" in s or "ë§ˆì¼“" in s:
        return "transaction_marketplace"
    if "enterprise" in s or "ì—”í„°í”„ë¼ì´ì¦ˆ" in s or "ì„¸ì¼ì¦ˆ" in s:
        return "enterprise_sales"

    return None


# -----------------------------
# 2) Helpers: íŒŒì¼/í…ìŠ¤íŠ¸/JSON
# -----------------------------
def save_uploaded_pdf(uploaded) -> str:
    os.makedirs("data/uploads", exist_ok=True)
    path = os.path.join("data/uploads", uploaded.name)
    with open(path, "wb") as f:
        f.write(uploaded.getbuffer())
    return path


def write_md(path: str, content: str) -> None:
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        f.write(content)


def build_packed_text(pages, limit_chars: int = 60000) -> str:
    parts = []
    for p in pages:
        t = (p.get("text") or "").strip()
        if t:
            parts.append(f"[PAGE {p['page']}]\n{t}")
    packed = "\n\n".join(parts)
    return packed[:limit_chars]


def safe_json_load(text: str):
    try:
        return json.loads(text)
    except Exception:
        s = (text or "").find("{")
        e = (text or "").rfind("}")
        if s != -1 and e != -1 and e > s:
            return json.loads(text[s:e + 1])
        return {"error": "JSON parse failed", "raw": text}


def extract_company_and_ceo(client, packed_text: str) -> dict:
    prompt = (
        "ë„ˆëŠ” IR PDFë¥¼ ì½ê³  'ê¸°ì—…ëª…'ê³¼ 'ëŒ€í‘œì ì„±ëª…'ì„ ì°¾ì•„ì•¼ í•œë‹¤.\n"
        "ì¶”ì •í•˜ì§€ ë§ê³ , ë¬¸ì„œì— ëª…ì‹œëœ ê·¼ê±° í˜ì´ì§€ì™€ ì§§ì€ ì¸ìš©ì„ í•¨ê»˜ ì œì‹œí•˜ë¼.\n"
        "ì¶œë ¥ì€ JSON ONLY: company_name, ceo_name, evidence[{page, quote}]\n\n"
        "IR í…ìŠ¤íŠ¸:\n"
    ) + packed_text
    resp = client.models.generate_content(model="gemini-2.5-flash", contents=prompt)
    return safe_json_load((resp.text or "").strip())


def classify_bm_industry_stage(client, company: str, ceo: str, packed_text: str, company_profile: dict) -> dict:
    ctx = {
        "company_name": company,
        "ceo_name": ceo,
        "ir_text_excerpt": packed_text[:8000],
        "company_profile": company_profile,
    }
    prompt = (
        "ë„ˆëŠ” ìŠ¤íƒ€íŠ¸ì—… IR ì‹¬ì‚¬ì—­ì´ë‹¤.\n"
        "ì•„ë˜ ì…ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸(BM), ì‚°ì—… ë¶„ì•¼, íˆ¬ììœ ì¹˜ ë‹¨ê³„(Stage)ë¥¼ ì¶”ì²œí•˜ë¼.\n"
        "ì¶”ì •ì´ ì–´ë µë‹¤ë©´ 'í™•ì¸ ë¶ˆê°€'ë¼ê³  ì“°ê³  ì´ìœ ë¥¼ ì§§ê²Œ ì¨ë¼.\n"
        "ì¶œë ¥ì€ JSON ONLY: business_model, industry, stage, reason\n\n"
        "business_model ì˜ˆ: SaaS/í”Œë«í¼/ì œì¡°/ë”¥í…Œí¬/ë°”ì´ì˜¤/ì»¤ë¨¸ìŠ¤/ì½˜í…ì¸ /ê¸°íƒ€\n"
        "industry ì˜ˆ: ëª¨ë¹Œë¦¬í‹°/í—¬ìŠ¤ì¼€ì–´/í•€í…Œí¬/AI/êµìœ¡/ë¦¬í…Œì¼/ê¸°íƒ€\n"
        "stage ì˜ˆ: Pre-seed/Seed/Pre-A/Series A/Series B+/í™•ì¸ ë¶ˆê°€\n\n"
        "ì…ë ¥:\n"
    ) + json.dumps(ctx, ensure_ascii=False)

    resp = client.models.generate_content(model="gemini-2.5-flash", contents=prompt)
    return safe_json_load((resp.text or "").strip())


def detect_scale_div(section_scores: dict) -> float:
    """
    evaluatorê°€ 0~10ì„ ë‚´ë©´ /2 í•´ì„œ 1~5 ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜í•´ì•¼ WeightEngineì— ë„£ê¸° ì¢‹ìŒ.
    0~5ë¥¼ ë‚´ë©´ ê·¸ëŒ€ë¡œ(1.0).
    """
    mx = 0.0
    for k in SECTIONS_KOR:
        try:
            mx = max(mx, float(section_scores.get(k, 0) or 0))
        except Exception:
            pass
    return 2.0 if mx > 5.5 else 1.0


# -----------------------------
# 3) ì—‘ì…€ ì»¬ëŸ¼(ìƒ˜í”Œ í¬ë§·)
# -----------------------------
COLUMNS = [
    "ë¶„ì„ ì¼ì‹œ", "íšŒì‚¬ëª…", "í•œì¤„ í”¼ì¹˜", "ì¢…í•© ì ìˆ˜", "íˆ¬ì ì¶”ì²œ", "ë¶„ì„ ë‹¨ê³„", "ë¶„ì„ ê´€ì ",
    "ë¬¸ì œ ì •ì˜ (ì ìˆ˜)", "ë¬¸ì œ ì •ì˜ (ë¶„ì„)", "ë¬¸ì œ ì •ì˜ (ê°œì„ ì•ˆ)",
    "ì†”ë£¨ì…˜ & ì œí’ˆ (ì ìˆ˜)", "ì†”ë£¨ì…˜ & ì œí’ˆ (ë¶„ì„)", "ì†”ë£¨ì…˜ & ì œí’ˆ (ê°œì„ ì•ˆ)",
    "ì‹œì¥ ë¶„ì„ (ì ìˆ˜)", "ì‹œì¥ ë¶„ì„ (ë¶„ì„)", "ì‹œì¥ ë¶„ì„ (ê°œì„ ì•ˆ)",
    "ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ (ì ìˆ˜)", "ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ (ë¶„ì„)", "ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ (ê°œì„ ì•ˆ)",
    "ê²½ìŸ ìš°ìœ„ (ì ìˆ˜)", "ê²½ìŸ ìš°ìœ„ (ë¶„ì„)", "ê²½ìŸ ìš°ìœ„ (ê°œì„ ì•ˆ)",
    "ì„±ì¥ ì „ëµ (ì ìˆ˜)", "ì„±ì¥ ì „ëµ (ë¶„ì„)", "ì„±ì¥ ì „ëµ (ê°œì„ ì•ˆ)",
    "íŒ€ ì—­ëŸ‰ (ì ìˆ˜)", "íŒ€ ì—­ëŸ‰ (ë¶„ì„)", "íŒ€ ì—­ëŸ‰ (ê°œì„ ì•ˆ)",
    "ì¬ë¬´ ê³„íš (ì ìˆ˜)", "ì¬ë¬´ ê³„íš (ë¶„ì„)", "ì¬ë¬´ ê³„íš (ê°œì„ ì•ˆ)",
    "ë¦¬ìŠ¤í¬ ê´€ë¦¬ (ì ìˆ˜)", "ë¦¬ìŠ¤í¬ ê´€ë¦¬ (ë¶„ì„)", "ë¦¬ìŠ¤í¬ ê´€ë¦¬ (ê°œì„ ì•ˆ)",
    "í•µì‹¬ ê°•ì ", "ê°œì„  í•„ìš”", "ìµœì¢… ì˜ê²¬", "ìŠ¤í† ë¦¬ë¼ì¸"
]


# -----------------------------
# 4) Streamlit UI
# -----------------------------
st.set_page_config(page_title="AI ì‹¬ì‚¬ì—­ (Lite+Engine)", layout="wide")
st.title("AI ì‹¬ì‚¬ì—­ powered by MARK")

st.sidebar.header("ì˜µì…˜")
use_company_profile = st.sidebar.toggle("íšŒì‚¬ ì„¤ëª…ë¬¸(í™ˆí˜ì´ì§€/ë‰´ìŠ¤) ìƒì„±", value=True)
use_visual_insights = st.sidebar.toggle("í‘œ/ì°¨íŠ¸/ê·¸ë˜í”„ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ", value=True)

# --- OCR/ìºì‹œ ì˜µì…˜ ---
keep_images = st.sidebar.toggle("OCR ìºì‹œ PNG ë³´ê´€(ìš©ëŸ‰â†‘)", value=True)
min_chars_retry = st.sidebar.number_input("ì§§ì€ í˜ì´ì§€ ì¬ì‹œë„ ê¸°ì¤€(ê¸€ììˆ˜)", min_value=0, max_value=1000, value=120, step=10)
ocr_timeout_sec = st.sidebar.number_input("í˜ì´ì§€ OCR íƒ€ì„ì•„ì›ƒ(ì´ˆ)", min_value=10, max_value=300, value=90, step=10)
cache_keep_days = st.sidebar.number_input("OCR ìºì‹œ ë³´ê´€ì¼(ì¼)", min_value=1, max_value=365, value=30, step=1)

if st.sidebar.button("ğŸ§¹ OCR ìºì‹œ ì •ë¦¬(ë³´ê´€ì¼ ì´ˆê³¼ ì‚­ì œ)"):
    cutoff = time.time() - int(cache_keep_days) * 86400
    removed = 0
    for d in glob.glob("data/ocr_cache/*"):
        try:
            if os.path.isdir(d) and os.path.getmtime(d) < cutoff:
                shutil.rmtree(d, ignore_errors=True)
                removed += 1
        except Exception:
            pass
    st.sidebar.success(f"ì‚­ì œ ì™„ë£Œ: {removed}ê°œ ìºì‹œ í´ë”")
reocr = st.sidebar.toggle("OCR ìºì‹œ ë¬´ì‹œ(ì¬ì¶”ì¶œ)", value=False)
dpi = st.sidebar.slider("OCR ë Œë” DPI", min_value=180, max_value=300, value=220, step=20)

uploaded_files = st.file_uploader("IR PDF ì—…ë¡œë“œ(ìµœëŒ€ 10ê°œ)", type=["pdf"], accept_multiple_files=True)
run_btn = st.button("ë¶„ì„ ì‹¤í–‰", type="primary", disabled=not uploaded_files)

if "result_cache" not in st.session_state:
    st.session_state.result_cache = {}
if "rows" not in st.session_state:
    st.session_state.rows = []

if "selected_report_path" not in st.session_state:
    st.session_state.selected_report_path = None
if "view_mode" not in st.session_state:
    st.session_state.view_mode = "list"  # "list" or "detail"


# -----------------------------
# 5) Main run
# -----------------------------
if run_btn:
    engine = WeightEngine()
    client = get_client()
    st.session_state.rows = []

    # evaluator_simple ì‹œê·¸ë‹ˆì²˜(ë²„ì „ í˜¸í™˜)
    sig = inspect.signature(run_overall_evaluation)
    has_weights_100 = "weights_100" in sig.parameters
    has_weights = "weights" in sig.parameters

    for up in uploaded_files[:10]:
        file_key = hashlib.md5(up.getvalue()).hexdigest()[:10]
        st.sidebar.caption(f"ì²˜ë¦¬ì¤‘: {up.name} | cache_key={file_key} | dpi={dpi} | reocr={reocr}")
        if file_key in st.session_state.result_cache:
            st.session_state.rows.append(st.session_state.result_cache[file_key])
            continue

        # PDF ì½ê¸° (ê°•ì œ OCR: ì „ í˜ì´ì§€ ì´ë¯¸ì§€ ê¸°ë°˜)
        pdf_bytes = up.getvalue()
        pdf_path = save_uploaded_pdf(up)

        ocr_cache_dir = f"data/ocr_cache/{file_key}"
        # OCR ì§„í–‰ë¥  í‘œì‹œ
        ocr_prog = st.progress(0)
        ocr_msg = st.empty()

        def _ocr_progress_cb(page_no, total_pages, stage, extra):
            pct = int(page_no * 100 / max(total_pages, 1))
            ocr_prog.progress(pct)
            ocr_msg.caption(f"OCR {page_no}/{total_pages} ({pct}%) - {stage}")
        pages = ocr_pdf_all_pages(
            client=client,
            pdf_path=pdf_path,
            cache_dir=ocr_cache_dir,
            dpi=dpi,
            model_name="gemini-2.5-flash",
            reocr=reocr,
            max_chars_per_page=8000,
            timeout_sec=ocr_timeout_sec,
            keep_images=keep_images,
            min_chars_retry=min_chars_retry,
            progress_callback=_ocr_progress_cb,
        )

        packed_text = build_packed_text(pages, limit_chars=90000)
        # fulltext ìƒì„± (í˜ì´ì§€ë³„ OCR í…ìŠ¤íŠ¸ë¥¼ ìˆœì„œëŒ€ë¡œ ì—°ê²°)
        from src.fulltext_from_cache import build_fulltext_from_pages_dir
        fulltext = build_fulltext_from_pages_dir(os.path.join(ocr_cache_dir, "pages"))

        # (ì„ íƒ) í‘œ/ì°¨íŠ¸/ê·¸ë˜í”„ ë³´ì¡° ì¸ì‚¬ì´íŠ¸(ì¶”ê°€ í˜¸ì¶œ)
        if use_visual_insights:
            try:
                vis = gemini_pdf_visual_insights(
                    client, pdf_bytes, model_name="gemini-2.5-flash", max_chars=12000
                )
                if vis and vis.strip():
                    packed_text = (packed_text + "\n\n" + vis)[:90000]
            except Exception:
                pass

        if show_debug:
            ocr_total_chars = sum(len((p.get("text") or "").strip()) for p in pages)
            nonempty_pages = sum(1 for p in pages if (p.get("text") or "").strip())
            st.sidebar.markdown("### [PDF OCR ë””ë²„ê·¸]")
            st.sidebar.caption(f"file: {up.name}")
            st.sidebar.caption(f"pages={len(pages)}, nonempty_pages={nonempty_pages}")
            st.sidebar.caption(f"ocr_total_chars={ocr_total_chars}")
            st.sidebar.caption(f"packed len={len(packed_text)}")
            st.sidebar.caption(f"ocr cache dir: {ocr_cache_dir}")

        # ê¸°ì—…/ëŒ€í‘œ ì¶”ì¶œ
        extracted = extract_company_and_ceo(client, packed_text)
        company = extracted.get("company_name") or "unknown_company"
        ceo = extracted.get("ceo_name") or "unknown_ceo"


        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        out_dir = f"data/outputs/{company}/{ts}"

        # fulltext ì €ì¥
        os.makedirs(out_dir, exist_ok=True)
        with open(f"{out_dir}/01_fulltext.txt", "w", encoding="utf-8") as f:
            f.write(fulltext)

        write_md(
            f"{out_dir}/00_extract.md",
            f"# ê¸°ì—…ëª…/ëŒ€í‘œì ì¶”ì¶œ\n- íŒŒì¼: {up.name}\n\n"
            f"- ê¸°ì—…ëª…: {company}\n- ëŒ€í‘œì: {ceo}\n\n"
            f"ê·¼ê±°:\n{json.dumps(extracted.get('evidence', []), ensure_ascii=False, indent=2)}\n"
        )

        # íšŒì‚¬ ì„¤ëª…ë¬¸(í™ˆí˜ì´ì§€/ë‰´ìŠ¤ ê¸°ë°˜)
        profile = {}
        profile_sources = []
        if use_company_profile and company != "unknown_company":
            try:
                profile, profile_sources = generate_company_profile(client, company, ceo)
                write_md(
                    f"{out_dir}/01_company_profile.md",
                    f"# íšŒì‚¬ ì„¤ëª…ë¬¸(í™ˆí˜ì´ì§€/ë‰´ìŠ¤ ê¸°ë°˜)\n- íšŒì‚¬ëª…: {company}\n- ëŒ€í‘œì: {ceo}\n\n"
                    f"```json\n{json.dumps(profile, ensure_ascii=False, indent=2)}\n```\n\n"
                    f"ì¶œì²˜:\n{json.dumps(profile_sources, ensure_ascii=False, indent=2)}\n"
                )
            except Exception as e:
                profile = {"error": str(e)}

        # BM/ì‚°ì—…/ë‹¨ê³„ ì¶”ì¶œ
        cls = classify_bm_industry_stage(client, company, ceo, packed_text, profile if isinstance(profile, dict) else {})
        bm = (cls.get("business_model") or "í™•ì¸ ë¶ˆê°€").strip()
        industry = (cls.get("industry") or "í™•ì¸ ë¶ˆê°€").strip()
        stage = (cls.get("stage") or "í™•ì¸ ë¶ˆê°€").strip()

        # âœ… WeightEngine ê°€ì¤‘ì¹˜(í•© 100)
        stage_key = map_stage_for_engine(stage)
        industry_key = map_industry_for_engine(industry)
        bm_key = map_bm_for_engine(bm)
        weights_100 = engine.compute_weights(stage=stage_key, industry=industry_key, business_model=bm_key)

        # âœ… evaluator ì‹¤í–‰(ë²„ì „ í˜¸í™˜)
        if has_weights_100:
            eval_json = run_overall_evaluation(
                client=client,
                model_name="gemini-2.5-flash",
                company=company,
                ceo=ceo,
                bm=bm,
                industry=industry,
                stage=stage,
                weights_100=weights_100,
                ir_text_with_pages=packed_text,
                company_profile_json=profile if isinstance(profile, dict) else {},
            )
        elif has_weights:
            weights_1 = {k: v / 100.0 for k, v in weights_100.items()}
            eval_json = run_overall_evaluation(
                client=client,
                model_name="gemini-2.5-flash",
                company=company,
                ceo=ceo,
                bm=bm,
                industry=industry,
                stage=stage,
                weights=weights_1,
                ir_text_with_pages=packed_text,
                company_profile_json=profile if isinstance(profile, dict) else {},
            )
        else:
            eval_json = run_overall_evaluation(
                client=client,
                model_name="gemini-2.5-flash",
                company=company,
                ceo=ceo,
                bm=bm,
                industry=industry,
                stage=stage,
                ir_text_with_pages=packed_text,
                company_profile_json=profile if isinstance(profile, dict) else {},
            )

        section_scores = eval_json.get("section_scores", {}) or {}
        scale_div = detect_scale_div(section_scores)

        # âœ… WeightEngine ì…ë ¥(1~5)
        scores_1_to_5 = {}
        for kor, crit in KOR_TO_CRITERION.items():
            try:
                scores_1_to_5[crit] = float(section_scores.get(kor, 0) or 0) / scale_div
            except Exception:
                scores_1_to_5[crit] = 0.0

        engine_out = engine.evaluate(
            scores_1_to_5=scores_1_to_5,
            stage=stage_key,
            industry=industry_key,
            business_model=bm_key,
            apply_gating=True,
        )
        total_100 = float(engine_out["overall_100_after_gates"])
        recommend = "YES" if total_100 >= 80 else "NO"

        # ---- report.json ì €ì¥(ìƒì„¸ í™”ë©´ ë Œë”ìš©) ----
        report_payload = {
            "file_name": up.name,
            "company_name": company,
            "ceo_name": ceo,
            "bm": bm,
            "industry": industry,
            "stage": stage,
	    "total_100": float(total_100),
	    "recommend": recommend,
	    "weights_100": weights_100,    # WeightEngine compute_weights ê²°ê³¼(í•© 100)
	    "engine_out": engine_out,      # gates_applied í¬í•¨
	    "eval": eval_json,             # section_scores/analysis/improvements/ìš”ì•½
        }
        with open(f"{out_dir}/report.json", "w", encoding="utf-8") as f:
            json.dump(report_payload, f, ensure_ascii=False, indent=2)


        # ---- ai_outputs.xlsx ì—…ì„œíŠ¸(í•™ìŠµ ë°ì´í„° ëˆ„ì ) ----
        row_out = {
            "file_name": up.name,
            "company_name": company,
            "ceo_name": ceo,
            "bm": bm,
            "industry": industry,
            "stage": stage,

            # evaluator ì¶œë ¥ ì ìˆ˜ ìŠ¤ì¼€ì¼(0~5 ë˜ëŠ” 0~10)ì„ ê·¸ëŒ€ë¡œ ì €ì¥
            "score_problem": float(section_scores.get("ë¬¸ì œ ì •ì˜", 0) or 0),
            "score_solution": float(section_scores.get("ì†”ë£¨ì…˜ & ì œí’ˆ", 0) or 0),
            "score_market": float(section_scores.get("ì‹œì¥ ë¶„ì„", 0) or 0),
            "score_business_model": float(section_scores.get("ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸", 0) or 0),
            "score_competition": float(section_scores.get("ê²½ìŸ ìš°ìœ„", 0) or 0),
            "score_growth": float(section_scores.get("ì„±ì¥ ì „ëµ", 0) or 0),
            "score_team": float(section_scores.get("íŒ€ ì—­ëŸ‰", 0) or 0),
            "score_finance": float(section_scores.get("ì¬ë¬´ ê³„íš", 0) or 0),
            "score_risk": float(section_scores.get("ë¦¬ìŠ¤í¬ ê´€ë¦¬", 0) or 0),

            "ai_raw_total_score": float(total_100),
            "ai_recommend_raw": recommend,

            "model_name": "gemini-2.5-flash",
            "prompt_version": "v_engine_applied",
        }
        upsert_ai_output(row_out)

        # 04_overall.md
        write_md(
            f"{out_dir}/04_overall.md",
            f"# ì¢…í•© í‰ê°€(ìš”ì•½)\n- íšŒì‚¬ëª…: {company}\n- ëŒ€í‘œì: {ceo}\n- BM: {bm}\n- ì‚°ì—…: {industry}\n- ë‹¨ê³„: {stage}\n"
            f"- ì´ì (0~100): {total_100}\n- ì¶”ì²œ(80+): {recommend}\n\n"
            f"## í•œì¤„ í”¼ì¹˜\n{eval_json.get('one_line_pitch', '')}\n\n"
            f"## ìµœì¢… ì˜ê²¬\n{eval_json.get('final_opinion', '')}\n"
        )

        # ì—‘ì…€ row êµ¬ì„±
        row = {c: "" for c in COLUMNS}
        row["ë¶„ì„ ì¼ì‹œ"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        row["íšŒì‚¬ëª…"] = company
        row["í•œì¤„ í”¼ì¹˜"] = eval_json.get("one_line_pitch", "")
        row["ì¢…í•© ì ìˆ˜"] = float(total_100)
        row["íˆ¬ì ì¶”ì²œ"] = recommend
        row["ë¶„ì„ ë‹¨ê³„"] = stage
        row["ë¶„ì„ ê´€ì "] = "íˆ¬ìì ê´€ì "

        analysis = eval_json.get("section_analysis", {}) or {}
        improvements = eval_json.get("section_improvements", {}) or {}

        def fill(sec_name: str, col_prefix: str):
            s = float(section_scores.get(sec_name, 0) or 0)
            row[f"{col_prefix} (ì ìˆ˜)"] = s
            row[f"{col_prefix} (ë¶„ì„)"] = analysis.get(sec_name, "")
            row[f"{col_prefix} (ê°œì„ ì•ˆ)"] = improvements.get(sec_name, "")

        fill("ë¬¸ì œ ì •ì˜", "ë¬¸ì œ ì •ì˜")
        fill("ì†”ë£¨ì…˜ & ì œí’ˆ", "ì†”ë£¨ì…˜ & ì œí’ˆ")
        fill("ì‹œì¥ ë¶„ì„", "ì‹œì¥ ë¶„ì„")
        fill("ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸", "ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸")
        fill("ê²½ìŸ ìš°ìœ„", "ê²½ìŸ ìš°ìœ„")
        fill("ì„±ì¥ ì „ëµ", "ì„±ì¥ ì „ëµ")
        fill("íŒ€ ì—­ëŸ‰", "íŒ€ ì—­ëŸ‰")
        fill("ì¬ë¬´ ê³„íš", "ì¬ë¬´ ê³„íš")
        fill("ë¦¬ìŠ¤í¬ ê´€ë¦¬", "ë¦¬ìŠ¤í¬ ê´€ë¦¬")

        row["í•µì‹¬ ê°•ì "] = eval_json.get("key_strengths", "")
        row["ê°œì„  í•„ìš”"] = eval_json.get("needs_improvement", "")
        row["ìµœì¢… ì˜ê²¬"] = eval_json.get("final_opinion", "")
        row["ìŠ¤í† ë¦¬ë¼ì¸"] = eval_json.get("storyline", "")

        st.session_state.result_cache[file_key] = row
        st.session_state.rows.append(row)

        append_history({
            "company_name": company,
            "ceo_name": ceo,
            "bm": bm,
            "industry": industry,
            "stage": stage,
            "total_score": float(total_100),
            "recommendation": recommend,
            "file_name": up.name,
            "output_path": out_dir
        })


# -----------------------------
# Results table + download
# -----------------------------
if st.session_state.rows:
    st.subheader("ê²°ê³¼ í…Œì´ë¸”(ìƒ˜í”Œ ì—‘ì…€ ì»¬ëŸ¼ ë™ì¼)")
    df = pd.DataFrame(st.session_state.rows, columns=COLUMNS)
    st.dataframe(df, use_container_width=True, height=420)

    buf = io.BytesIO()
    df.to_excel(buf, index=False)
    st.download_button(
        "ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
        data=buf.getvalue(),
        file_name="InnoForest_Detailed_Report_output.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    )

st.markdown("## íˆìŠ¤í† ë¦¬(ê¸°ì¡´ history.xlsx)")
hist = load_history()
st.dataframe(hist, use_container_width=True)

st.markdown("## AI Outputs (íŠœë‹ìš© ë°ì´í„°ì…‹)")
try:
    df_ai = load_ai_outputs()
    st.dataframe(df_ai, use_container_width=True, height=260)

    buf2 = io.BytesIO()
    df_ai.to_excel(buf2, index=False)
    st.download_button(
        "ai_outputs.xlsx ë‹¤ìš´ë¡œë“œ",
        data=buf2.getvalue(),
        file_name="ai_outputs.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    )
    st.caption(f"ì €ì¥ ê²½ë¡œ: {AI_OUTPUT_PATH}")
except Exception as e:
    st.warning(f"AI Outputs í‘œì‹œ ì‹¤íŒ¨: {e}")

# -----------------------------
# ìƒì„¸ ë¦¬í¬íŠ¸ ë Œë” í•¨ìˆ˜
# -----------------------------
def radar_chart(scores_dict, labels_kor):
    values = [float(scores_dict.get(k, 0) or 0) for k in labels_kor]
    N = len(values)
    angles = [2 * math.pi * n / N for n in range(N)]
    values += values[:1]
    angles += angles[:1]

    fig = plt.figure(figsize=(4, 4))
    ax = fig.add_subplot(111, polar=True)
    ax.plot(angles, values)
    ax.fill(angles, values, alpha=0.15)
    ax.set_xticks(angles[:-1])
    ax.set_xticklabels(labels_kor, fontsize=8)
    return fig

def render_report(report: dict):
    eval_json = report.get("eval", {}) or {}
    section_scores = eval_json.get("section_scores", {}) or {}
    section_analysis = eval_json.get("section_analysis", {}) or {}
    section_improvements = eval_json.get("section_improvements", {}) or {}

    weights_100 = report.get("weights_100", {}) or {}
    engine_out = report.get("engine_out", {}) or {}
    gates = engine_out.get("gates_applied", []) or []

    st.markdown(f"## {report.get('company_name','')} â€” ë¶„ì„ ë¦¬í¬íŠ¸")
    st.caption(
        f"file: {report.get('file_name','')} | stage: {report.get('stage','')} | "
        f"bm: {report.get('bm','')} | industry: {report.get('industry','')}"
    )
    st.metric("ì´ì (0~100)", report.get("total_100", ""))
    st.caption(f"ì¶”ì²œ(80+): {report.get('recommend','')}")

    left, right = st.columns([1, 2], gap="large")

    with left:
        st.subheader("Visual Score Balance")
        fig = radar_chart(section_scores, SECTIONS_KOR)
        st.pyplot(fig, clear_figure=True)

        st.subheader("Executive Summary")
        st.write(eval_json.get("final_opinion", "") or "")

        if gates:
            st.subheader("Gatekeeper's Verdict")
            for g in gates[:5]:
                st.write(f"- **{g.get('gate','')}**: {g.get('note','')}")
                st.caption(f"criterion={g.get('criterion')} | before={g.get('before_100')} â†’ after={g.get('after_100')}")

    with right:
        st.subheader("Detailed Analysis")
        for k in SECTIONS_KOR:
            crit_key = KOR_TO_CRITERION.get(k)
            w = float(weights_100.get(crit_key, 0) or 0)
            s = float(section_scores.get(k, 0) or 0)
            weighted = round(s * (w / 100.0), 2)

            with st.container(border=True):
                c1, c2 = st.columns([3, 1])
                with c1:
                    st.markdown(f"### {k}")
                with c2:
                    st.write(f"**{s}**")
                    st.caption(f"w={w:.1f}%")

                st.caption(f"Weighted: {weighted}")

                st.markdown("**ANALYSIS**")
                st.write(section_analysis.get(k, "") or "")

                st.markdown("**IMPROVEMENT**")
                st.write(section_improvements.get(k, "") or "")

# -----------------------------
# ìƒì„¸ í™”ë©´ ëª¨ë“œë©´ ë¨¼ì € ë³´ì—¬ì£¼ê³  ì¢…ë£Œ
# -----------------------------
if st.session_state.view_mode == "detail":
    if st.button("â† ë¦¬ìŠ¤íŠ¸ë¡œ ëŒì•„ê°€ê¸°"):
        st.session_state.view_mode = "list"
        st.session_state.selected_report_path = None
        st.rerun()

    rp = st.session_state.selected_report_path
    if not rp or not os.path.exists(rp):
        st.error("report.jsonì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        with open(rp, "r", encoding="utf-8") as f:
            report = json.load(f)
        render_report(report)

    st.stop()

# -----------------------------
# ë¦¬ìŠ¤íŠ¸(íˆìŠ¤í† ë¦¬ ê¸°ë°˜) + 'ë¶„ì„ê²°ê³¼ ë³´ê¸°' ë²„íŠ¼
# -----------------------------
st.markdown("## ë¶„ì„ íŒŒì¼ ë¦¬ìŠ¤íŠ¸")
hist = load_history()

if hist.empty:
    st.info("íˆìŠ¤í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
else:
    # ìµœì‹ ìˆœ(ìµœê·¼ 50ê°œë§Œ)
    view = hist.tail(50).reset_index(drop=True)

    for i, r in view.iterrows():
        col1, col2, col3, col4, col5 = st.columns([3, 2, 1, 1, 2])
        with col1:
            st.write(f"**{r.get('company_name','')}**  ({r.get('file_name','')})")
        with col2:
            st.write(f"Score: {r.get('total_score','')}")
        with col3:
            st.write(f"Rec: {r.get('recommendation','')}")
        with col4:
            st.write(r.get("stage", ""))
        with col5:
            if st.button("ë¶„ì„ê²°ê³¼ ë³´ê¸°", key=f"view_{i}"):
                report_path = os.path.join(str(r.get("output_path","")), "report.json")
                st.session_state.selected_report_path = report_path
                st.session_state.view_mode = "detail"
                st.rerun()
st.sidebar.caption("PDFëŠ” ì „ í˜ì´ì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•œ ë’¤ OCRë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤(ê³ ì •).")
